{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc57893-3dbf-4ddc-9a5f-3e6989428d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Kalman Filter implementation\n",
    "class KalmanFilter:\n",
    "    def __init__(self, initial_state, initial_uncertainty, measurement_uncertainty, process_uncertainty):\n",
    "        # Initial state (position and velocity)\n",
    "        self.state = initial_state  # [position, velocity]\n",
    "        \n",
    "        # Initial state uncertainty (covariance matrix)\n",
    "        self.P = initial_uncertainty\n",
    "        \n",
    "        # Measurement uncertainty\n",
    "        self.R = measurement_uncertainty\n",
    "        \n",
    "        # Process uncertainty (how much we trust our model)\n",
    "        self.Q = process_uncertainty\n",
    "        \n",
    "        # State transition matrix (assuming constant velocity model)\n",
    "        self.F = np.array([[1, 1],  # Position update: x(t) = x(t-1) + v(t-1)\n",
    "                           [0, 1]]) # Velocity update: v(t) = v(t-1)\n",
    "        \n",
    "        # Measurement matrix (we directly measure position)\n",
    "        self.H = np.array([[1, 0]])  # We only measure position, not velocity\n",
    "    \n",
    "    def predict(self):\n",
    "        # Prediction Step\n",
    "        self.state = np.dot(self.F, self.state)  # Predicted state\n",
    "        self.P = np.dot(np.dot(self.F, self.P), self.F.T) + self.Q  # Predicted uncertainty\n",
    "\n",
    "    def update(self, measurement):\n",
    "        # Update Step\n",
    "        # Compute the Kalman gain\n",
    "        S = np.dot(np.dot(self.H, self.P), self.H.T) + self.R\n",
    "        K = np.dot(np.dot(self.P, self.H.T), np.linalg.inv(S))\n",
    "        \n",
    "        # Update the state estimate with the measurement\n",
    "        y = measurement - np.dot(self.H, self.state)  # Measurement residual\n",
    "        self.state = self.state + np.dot(K, y)\n",
    "        \n",
    "        # Update the uncertainty\n",
    "        self.P = self.P - np.dot(np.dot(K, self.H), self.P)\n",
    "\n",
    "# Simulation parameters\n",
    "num_steps = 50  # Number of time steps\n",
    "true_position = 0  # True initial position\n",
    "true_velocity = 1  # True initial velocity (constant velocity)\n",
    "\n",
    "# Generate synthetic noisy measurements\n",
    "np.random.seed(0)  # For reproducibility\n",
    "measurements = []\n",
    "for i in range(num_steps):\n",
    "    noise = np.random.normal(0, 2)  # Measurement noise\n",
    "    true_position += true_velocity  # Update true position\n",
    "    noisy_measurement = true_position + noise\n",
    "    measurements.append(noisy_measurement)\n",
    "\n",
    "# Initial state estimate (position, velocity) and uncertainty\n",
    "initial_state = np.array([0, 1])  # Initial guess for position and velocity\n",
    "initial_uncertainty = np.array([[1000, 0],  # High uncertainty about initial state\n",
    "                                [0, 1000]])\n",
    "\n",
    "# Measurement uncertainty and process uncertainty\n",
    "measurement_uncertainty = 4  # The variance in our measurements (e.g., sensor noise)\n",
    "process_uncertainty = np.array([[1, 0],  # Assume some process noise for both position and velocity\n",
    "                                [0, 1]])\n",
    "\n",
    "# Create the Kalman Filter object\n",
    "kf = KalmanFilter(initial_state, initial_uncertainty, measurement_uncertainty, process_uncertainty)\n",
    "\n",
    "# Apply Kalman filter to measurements\n",
    "estimated_positions = []\n",
    "estimated_velocities = []\n",
    "\n",
    "for measurement in measurements:\n",
    "    kf.predict()  # Prediction step\n",
    "    kf.update(measurement)  # Update step\n",
    "    estimated_positions.append(kf.state[0])\n",
    "    estimated_velocities.append(kf.state[1])\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot true position, noisy measurements, and estimated position\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(estimated_positions, label='Estimated Position', color='b')\n",
    "plt.scatter(range(num_steps), measurements, color='r', label='Noisy Measurements', alpha=0.5)\n",
    "plt.plot(range(num_steps), np.arange(num_steps) + true_velocity * np.arange(num_steps), label='True Position', color='g')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Position')\n",
    "plt.legend()\n",
    "plt.title('Position Estimation')\n",
    "\n",
    "# Plot estimated velocity\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(estimated_velocities, label='Estimated Velocity', color='b')\n",
    "plt.axhline(true_velocity, color='g', linestyle='--', label='True Velocity')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Velocity')\n",
    "plt.legend()\n",
    "plt.title('Velocity Estimation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f53d4-a7f7-4136-ba39-6d9cfd812904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "import numpy as np\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normalize the pixel values of an image to be between 0 and 1.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: numpy array of shape (H, W, C) or (H, W), where H is the height,\n",
    "             W is the width, and C is the number of color channels (3 for RGB).\n",
    "    \n",
    "    Returns:\n",
    "    - Normalized image: numpy array with pixel values between 0 and 1.\n",
    "    \"\"\"\n",
    "    # Ensure the image is in float32 format for accurate division\n",
    "    normalized_image = image.astype(np.float32)\n",
    "    \n",
    "    # Normalize the pixel values to [0, 1]\n",
    "    normalized_image /= 255.0\n",
    "    \n",
    "    return normalized_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f1590-1b57-41a0-b050-b71ad3953768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "import numpy as np\n",
    "\n",
    "def generate_dummy_detections(num_detections, image_shape=(640, 480), confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Generate dummy object detection data with confidence scores and bounding boxes, \n",
    "    and filter detections based on a confidence threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    - num_detections: The number of dummy detections to generate.\n",
    "    - image_shape: Tuple representing the shape of the image (height, width).\n",
    "    - confidence_threshold: Confidence score threshold for filtering detections.\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_boxes: List of bounding boxes for detections with confidence > threshold.\n",
    "    - filtered_scores: List of confidence scores for detections with confidence > threshold.\n",
    "    \"\"\"\n",
    "    # Generate random bounding boxes within the image dimensions\n",
    "    height, width = image_shape\n",
    "    boxes = np.random.randint(0, min(height, width), size=(num_detections, 4))\n",
    "    \n",
    "    # Ensure boxes are valid: (x1 < x2) and (y1 < y2)\n",
    "    boxes[:, 2] = np.clip(boxes[:, 2], boxes[:, 0] + 1, width)  # x2 should be > x1\n",
    "    boxes[:, 3] = np.clip(boxes[:, 3], boxes[:, 1] + 1, height)  # y2 should be > y1\n",
    "    \n",
    "    # Generate random confidence scores between 0 and 1\n",
    "    confidence_scores = np.random.rand(num_detections)\n",
    "    \n",
    "    # Filter detections based on the confidence threshold\n",
    "    filtered_indices = confidence_scores > confidence_threshold\n",
    "    filtered_boxes = boxes[filtered_indices]\n",
    "    filtered_scores = confidence_scores[filtered_indices]\n",
    "    \n",
    "    return filtered_boxes, filtered_scores\n",
    "\n",
    "# Example usage\n",
    "num_detections = 10\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "# Generate dummy data\n",
    "boxes, scores = generate_dummy_detections(num_detections, confidence_threshold=confidence_threshold)\n",
    "\n",
    "# Print the results\n",
    "print(\"Bounding Boxes (x1, y1, x2, y2):\")\n",
    "print(boxes)\n",
    "print(\"\\nConfidence Scores:\")\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40931c66-f69e-4f71-8a6f-6d465b1793c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "import numpy as np\n",
    "\n",
    "def extract_features_from_yolo_detections(detections, feature_dim=128):\n",
    "    \"\"\"\n",
    "    Given a list of YOLO detections, generate a random 128-dimensional feature vector for each detection.\n",
    "    \n",
    "    Parameters:\n",
    "    - detections: List of YOLO detections. Each detection is expected to be a tuple/list\n",
    "                  in the form (x_center, y_center, width, height, class_id, confidence).\n",
    "    - feature_dim: The dimensionality of the feature vector (default is 128).\n",
    "    \n",
    "    Returns:\n",
    "    - feature_vectors: A list of 128-dimensional feature vectors, one for each detection.\n",
    "    \"\"\"\n",
    "    feature_vectors = []\n",
    "    \n",
    "    # Iterate over each detection and generate a random feature vector\n",
    "    for detection in detections:\n",
    "        # Optionally, you could use the detection's properties (e.g., bounding box, class) to influence the feature vector\n",
    "        # For simplicity, we generate a random feature vector here.\n",
    "        feature_vector = np.random.rand(feature_dim)\n",
    "        \n",
    "        # Append the feature vector to the list\n",
    "        feature_vectors.append(feature_vector)\n",
    "    \n",
    "    return feature_vectors\n",
    "\n",
    "# Example usage:\n",
    "# Let's assume we have a list of detections in the form (x_center, y_center, width, height, class_id, confidence)\n",
    "yolo_detections = [\n",
    "    (100, 150, 50, 60, 0, 0.98),  # Example detection 1\n",
    "    (200, 250, 80, 100, 1, 0.88),  # Example detection 2\n",
    "    (300, 350, 120, 150, 2, 0.93), # Example detection 3\n",
    "]\n",
    "\n",
    "# Extract random feature vectors for each detection\n",
    "feature_vectors = extract_features_from_yolo_detections(yolo_detections)\n",
    "\n",
    "# Print the generated feature vectors\n",
    "for i, feature_vector in enumerate(feature_vectors):\n",
    "    print(f\"Detection {i+1} Feature Vector (128 dimensions):\\n{feature_vector}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe22ec3-2815-41e9-90e5-c6bbf94f2fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def reidentify_objects(current_features, previous_features, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Re-identify objects by matching feature vectors using Euclidean distance.\n",
    "\n",
    "    Parameters:\n",
    "    - current_features: A list/array of current detections' feature vectors (N x D),\n",
    "                         where N is the number of current detections, and D is the feature vector dimensionality.\n",
    "    - previous_features: A list/array of previous detections' feature vectors (M x D),\n",
    "                          where M is the number of previous detections, and D is the feature vector dimensionality.\n",
    "    - threshold: A distance threshold to consider if two objects are the same. If the distance is below this threshold,\n",
    "                 they are considered the same object.\n",
    "\n",
    "    Returns:\n",
    "    - matched_ids: A list of indices of the matched previous detections for each current detection.\n",
    "                   If no match is found (distance > threshold), -1 is returned for that detection.\n",
    "    \"\"\"\n",
    "    # Compute the Euclidean distance matrix between current and previous feature vectors\n",
    "    distances = cdist(current_features, previous_features, metric='euclidean')\n",
    "    \n",
    "    # Find the indices of the closest previous detections for each current detection\n",
    "    matched_ids = []\n",
    "    \n",
    "    for i, current_feat in enumerate(distances):\n",
    "        # Find the index of the minimum distance for the current detection\n",
    "        min_distance_idx = np.argmin(current_feat)\n",
    "        min_distance = current_feat[min_distance_idx]\n",
    "        \n",
    "        # Check if the minimum distance is below the threshold\n",
    "        if min_distance < threshold:\n",
    "            matched_ids.append(min_distance_idx)\n",
    "        else:\n",
    "            matched_ids.append(-1)  # No match if distance exceeds the threshold\n",
    "    \n",
    "    return matched_ids\n",
    "\n",
    "# Example usage:\n",
    "# Let's assume we have a list of feature vectors for current and previous detections\n",
    "current_features = np.random.rand(5, 128)  # 5 current detections with 128-dimensional feature vectors\n",
    "previous_features = np.random.rand(8, 128)  # 8 previous detections with 128-dimensional feature vectors\n",
    "\n",
    "# Re-identify objects based on feature vectors\n",
    "threshold = 0.5  # Distance threshold for matching objects\n",
    "matched_ids = reidentify_objects(current_features, previous_features, threshold)\n",
    "\n",
    "# Print the results\n",
    "print(\"Matched IDs (or -1 for no match):\")\n",
    "print(matched_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2076f8e4-a5a8-42a2-9212-097f11d16493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class KalmanTracker:\n",
    "    def __init__(self, initial_state=None):\n",
    "        # Initialize Kalman Filter\n",
    "        self.kf = cv2.KalmanFilter(4, 2)  # 4 state variables (x, y, vx, vy), 2 measurements (x, y)\n",
    "        \n",
    "        # State transition matrix (Assume constant velocity model)\n",
    "        self.kf.transitionMatrix = np.array([[1, 0, 1, 0],  # x = x + vx\n",
    "                                             [0, 1, 0, 1],  # y = y + vy\n",
    "                                             [0, 0, 1, 0],  # vx = vx\n",
    "                                             [0, 0, 0, 1]], # vy = vy\n",
    "        \n",
    "        # Measurement matrix (we only measure position)\n",
    "        self.kf.measurementMatrix = np.array([[1, 0, 0, 0],\n",
    "                                               [0, 1, 0, 0]], dtype=np.float32)\n",
    "        \n",
    "        # Process noise covariance (assume noise)\n",
    "        self.kf.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03\n",
    "        \n",
    "        # Measurement noise covariance\n",
    "        self.kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * 0.1\n",
    "        \n",
    "        # Initial state estimate: [x, y, vx, vy]\n",
    "        if initial_state is not None:\n",
    "            self.kf.statePost = np.array(initial_state, dtype=np.float32)\n",
    "        else:\n",
    "            self.kf.statePost = np.zeros(4, dtype=np.float32)  # Assuming initial position (0, 0) and velocity (0, 0)\n",
    "    \n",
    "    def predict(self):\n",
    "        # Predict the next state based on the current state\n",
    "        predicted_state = self.kf.predict()\n",
    "        return predicted_state[:2]  # Return predicted position (x, y)\n",
    "    \n",
    "    def update(self, measurement):\n",
    "        # Update the Kalman filter with a new measurement (detected object position)\n",
    "        self.kf.correct(measurement)\n",
    "        return self.kf.statePost[:2]  # Return updated position (x, y)\n",
    "\n",
    "\n",
    "def track_objects_with_kalman(yolo_detections, initial_positions=None):\n",
    "    \"\"\"\n",
    "    Tracks objects using Kalman Filter based on YOLO detections.\n",
    "    \n",
    "    Parameters:\n",
    "    - yolo_detections: List of detections with bounding boxes in the form (x_center, y_center, width, height)\n",
    "    - initial_positions: Initial positions of the objects to track (Optional)\n",
    "    \n",
    "    Returns:\n",
    "    - tracked_positions: List of positions for each object after tracking with Kalman Filter\n",
    "    \"\"\"\n",
    "    trackers = []\n",
    "    tracked_positions = []\n",
    "    \n",
    "    # Initialize Kalman trackers for each object\n",
    "    for i, detection in enumerate(yolo_detections):\n",
    "        x_center, y_center, _, _ = detection\n",
    "        \n",
    "        # If no initial positions are provided, initialize with YOLO center\n",
    "        if initial_positions is None:\n",
    "            initial_state = [x_center, y_center, 0, 0]  # Assume no velocity initially\n",
    "        else:\n",
    "            initial_state = initial_positions[i]\n",
    "        \n",
    "        kalman_tracker = KalmanTracker(initial_state)\n",
    "        trackers.append(kalman_tracker)\n",
    "    \n",
    "    # Update each tracker with the new YOLO detections\n",
    "    for i, detection in enumerate(yolo_detections):\n",
    "        x_center, y_center, _, _ = detection\n",
    "        \n",
    "        # Create a measurement (we only measure position)\n",
    "        measurement = np.array([[x_center], [y_center]], dtype=np.float32)\n",
    "        \n",
    "        # Update the Kalman filter and get the predicted position\n",
    "        tracked_position = trackers[i].update(measurement)\n",
    "        tracked_positions.append(tracked_position)\n",
    "    \n",
    "    return tracked_positions\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "yolo_detections = [\n",
    "    (100, 150, 50, 60),  # Example detection (x_center, y_center, width, height)\n",
    "    (200, 250, 80, 100),\n",
    "    (300, 350, 120, 150),\n",
    "]\n",
    "\n",
    "# Track objects using Kalman Filter\n",
    "tracked_positions = track_objects_with_kalman(yolo_detections)\n",
    "\n",
    "# Print the tracked positions\n",
    "for i, position in enumerate(tracked_positions):\n",
    "    print(f\"Tracked position for object {i+1}: {position}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fba16cc-6348-427b-8bfa-b122e0a37657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class KalmanFilter:\n",
    "    def __init__(self, initial_state, process_noise_cov, measurement_noise_cov):\n",
    "        # Kalman filter initialization\n",
    "        self.state = np.array(initial_state, dtype=np.float32)  # [x, y, vx, vy]\n",
    "        self.process_noise_cov = process_noise_cov  # Process noise covariance\n",
    "        self.measurement_noise_cov = measurement_noise_cov  # Measurement noise covariance\n",
    "        \n",
    "        # Kalman Filter Matrices\n",
    "        self.transition_matrix = np.array([[1, 0, 1, 0],\n",
    "                                           [0, 1, 0, 1],\n",
    "                                           [0, 0, 1, 0],\n",
    "                                           [0, 0, 0, 1]], dtype=np.float32)\n",
    "        \n",
    "        self.measurement_matrix = np.array([[1, 0, 0, 0],\n",
    "                                            [0, 1, 0, 0]], dtype=np.float32)\n",
    "        \n",
    "        self.process_noise_cov_matrix = np.eye(4, dtype=np.float32) * self.process_noise_cov\n",
    "        self.measurement_noise_cov_matrix = np.eye(2, dtype=np.float32) * self.measurement_noise_cov\n",
    "        self.state_covariance = np.eye(4, dtype=np.float32)  # Initial state covariance matrix\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\" Prediction step of the Kalman filter \"\"\"\n",
    "        self.state = np.dot(self.transition_matrix, self.state)  # Predict the next state\n",
    "        self.state_covariance = np.dot(np.dot(self.transition_matrix, self.state_covariance), self.transition_matrix.T) + self.process_noise_cov_matrix\n",
    "        return self.state[:2]  # Return predicted position (x, y)\n",
    "\n",
    "    def update(self, measurement):\n",
    "        \"\"\" Update step of the Kalman filter \"\"\"\n",
    "        innovation = measurement - np.dot(self.measurement_matrix, self.state)  # Measurement residual\n",
    "        innovation_covariance = np.dot(np.dot(self.measurement_matrix, self.state_covariance), self.measurement_matrix.T) + self.measurement_noise_cov_matrix\n",
    "        \n",
    "        kalman_gain = np.dot(np.dot(self.state_covariance, self.measurement_matrix.T), np.linalg.inv(innovation_covariance))\n",
    "        \n",
    "        self.state = self.state + np.dot(kalman_gain, innovation)  # Correct the predicted state\n",
    "        self.state_covariance = self.state_covariance - np.dot(np.dot(kalman_gain, self.measurement_matrix), self.state_covariance)  # Update covariance matrix\n",
    "        \n",
    "        return self.state[:2]  # Return updated position (x, y)\n",
    "\n",
    "def simulate_object_movement(true_position, velocity, num_steps, noise_level):\n",
    "    \"\"\" Simulate the movement of an object in 2D space with random noise \"\"\"\n",
    "    positions = [true_position]\n",
    "    for _ in range(num_steps):\n",
    "        true_position = true_position + velocity  # Update true position\n",
    "        noisy_position = true_position + np.random.normal(0, noise_level, 2)  # Add noise to the position\n",
    "        positions.append(noisy_position)\n",
    "    return np.array(positions)\n",
    "\n",
    "# Set initial conditions\n",
    "initial_position = np.array([0, 0], dtype=np.float32)  # Initial position (x, y)\n",
    "velocity = np.array([1, 1], dtype=np.float32)  # Velocity in (vx, vy)\n",
    "num_steps = 50  # Number of time steps to simulate\n",
    "noise_level = 0.5  # Standard deviation of noise\n",
    "process_noise_cov = 0.01  # Process noise covariance (reflects uncertainty in motion model)\n",
    "measurement_noise_cov = 1  # Measurement noise covariance (reflects sensor noise)\n",
    "\n",
    "# Simulate object movement with noise\n",
    "true_positions = simulate_object_movement(initial_position, velocity, num_steps, noise_level)\n",
    "\n",
    "# Initialize Kalman Filter\n",
    "kf = KalmanFilter(initial_state=[0, 0, 1, 1],  # Initial state [x, y, vx, vy]\n",
    "                  process_noise_cov=process_noise_cov,\n",
    "                  measurement_noise_cov=measurement_noise_cov)\n",
    "\n",
    "# Track object using Kalman Filter\n",
    "predicted_positions = []\n",
    "updated_positions = []\n",
    "\n",
    "for noisy_position in true_positions:\n",
    "    # Predict the next position\n",
    "    predicted_position = kf.predict()\n",
    "    predicted_positions.append(predicted_position)\n",
    "    \n",
    "    # Update Kalman Filter with noisy measurement\n",
    "    updated_position = kf.update(noisy_position)\n",
    "    updated_positions.append(updated_position)\n",
    "\n",
    "# Convert lists to numpy arrays for easy plotting\n",
    "predicted_positions = np.array(predicted_positions)\n",
    "updated_positions = np.array(updated_positions)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(true_positions[:, 0], true_positions[:, 1], label='True Position', color='g', linestyle='-', marker='o', markersize=5)\n",
    "plt.plot(true_positions[:, 0], true_positions[:, 1], label='Noisy Measurement', color='r', linestyle='--', marker='x', markersize=5)\n",
    "plt.plot(predicted_positions[:, 0], predicted_positions[:, 1], label='Predicted Position (Kalman)', color='b', linestyle='-.', marker='^', markersize=5)\n",
    "plt.plot(updated_positions[:, 0], updated_positions[:, 1], label='Updated Position (Kalman)', color='purple', linestyle='-', marker='s', markersize=5)\n",
    "\n",
    "plt.title(\"Object Tracking with Kalman Filter\")\n",
    "plt.xlabel(\"X Position\")\n",
    "plt.ylabel(\"Y Position\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
